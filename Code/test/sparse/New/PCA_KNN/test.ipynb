{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 251)\n",
      "(10, 251)\n",
      "data_real_scaled: (10, 251)\n",
      "data_imag_scaled: (10, 251)\n",
      "(10, 4)\n",
      "(10, 4)\n",
      "(10, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = np.random.randn(10, 251, 2)\n",
    "\n",
    "# Separate real and imaginary parts\n",
    "data_real = data[:, :, 0]  # Shape: (10, 251)\n",
    "data_imag = data[:, :, 1]  # Shape: (10, 251)\n",
    "print(data_real.shape)\n",
    "print(data_imag.shape)\n",
    "\n",
    "\n",
    "scaler_real = StandardScaler()\n",
    "data_real_scaled = scaler_real.fit_transform(data_real)\n",
    "print(f'data_real_scaled: {data_real_scaled.shape}')\n",
    "\n",
    "scaler_imag = StandardScaler()\n",
    "data_imag_scaled = scaler_imag.fit_transform(data_imag)\n",
    "print(f'data_imag_scaled: {data_imag_scaled.shape}')\n",
    "\n",
    "pca_components = 4\n",
    "pca_real = PCA(n_components=pca_components)\n",
    "data_real_pca = pca_real.fit_transform(data_real_scaled)  # Shape: (10, 4)\n",
    "print(data_real_pca.shape)\n",
    "\n",
    "pca_imag = PCA(n_components=pca_components)\n",
    "data_imag_pca = pca_imag.fit_transform(data_imag_scaled)  # Shape: (10, 4)\n",
    "print(data_imag_pca.shape)\n",
    "\n",
    "data_pca = np.stack((data_real_pca, data_imag_pca), axis=2)  # Shape: (10, 4, 2)\n",
    "print(data_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cir_transposed: (2, 251)\n",
      "cir_transposed: (2, 251)\n",
      "U_reduced: (2, 2)\n",
      "s_reduced: (2,)\n",
      "Vt_reduced: (2, 251)\n",
      "(1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Your original data of shape (10, 251, 2)\n",
    "data = np.random.randn(1, 251, 2)\n",
    "n_components = 4\n",
    "\n",
    "data_reduced = []\n",
    "for cir in data:\n",
    "    # cir has shape (251, 2)\n",
    "    # Transpose to (2, 251) to treat time steps as features\n",
    "    cir_transposed = cir.T  # Shape: (2, 251)\n",
    "    print(f'cir_transposed: {cir_transposed.shape}')\n",
    "    # Center the data (subtract the mean)\n",
    "    cir_transposed -= np.mean(cir_transposed, axis=1, keepdims=True)\n",
    "    print(f'cir_transposed: {cir_transposed.shape}')\n",
    "    # Perform SVD\n",
    "    U, s, Vt = np.linalg.svd(cir_transposed, full_matrices=False)\n",
    "    \n",
    "    # Keep top n_components singular values and vectors\n",
    "    U_reduced = U[:, :n_components]          # Shape: (2, n_components)\n",
    "    print(f'U_reduced: {U_reduced.shape}')\n",
    "    s_reduced = s[:n_components]             # Shape: (n_components,)\n",
    "    print(f's_reduced: {s_reduced.shape}')\n",
    "    Vt_reduced = Vt[:n_components, :]        # Shape: (n_components, 251)\n",
    "    print(f'Vt_reduced: {Vt_reduced.shape}')\n",
    "    # Project data onto the reduced singular vectors\n",
    "    cir_reduced = np.dot(U_reduced, np.diag(s_reduced))  # Shape: (2, n_components)\n",
    "    data_reduced.append(cir_reduced.T)  # Shape: (n_components, 2)\n",
    "\n",
    "data_reduced = np.array(data_reduced)  # Shape: (10, 3, 2)\n",
    "print(data_reduced.shape)  # Outputs: (10, 3, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 502)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = np.random.randn(10, 251, 2)\n",
    "data_reshape = data.reshape(data.shape[0], -1)\n",
    "print(data_reshape.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_reshape)\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca_data = pca.fit_transform(scaled_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
