{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainData - (6400, 15, 251, 2)\n",
      "testData - (1600, 15, 251, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "measurement = np.load('../../../dataset/meas_symm_1.npz', allow_pickle=False)\n",
    "header, data = measurement['header'], measurement['data']\n",
    "data_cir = data['cirs'][:8000]\n",
    "n_comp = 4\n",
    "\n",
    "# Train-test split\n",
    "trainCIR, testCIR = train_test_split(data_cir, test_size=0.2, random_state=42)\n",
    "print(f'trainData - {trainCIR.shape}')\n",
    "print(f'testData - {testCIR.shape}')\n",
    "\n",
    "# Define channels\n",
    "alice_channel = 3  # A -> B (legitimate)\n",
    "eve_channel = 6  # E -> B (illegitimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our dataset - (12800, 251, 2)\n",
    "\n",
    "def apply_pca(data, n_components=n_comp):\n",
    "    # data: (cirs, 251, 2) -> \n",
    "\n",
    "    reshaped_data = data.reshape(-1, 251)  # (cirs * 2, 251) -> (12800 * 2, 251) -> (25600, 251)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(reshaped_data) # (25600, 251)\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    data_pca = pca.fit_transform(data_scaled) # (cirs * 2, n_components) -> (25600, 4)\n",
    "    data_pca = data_pca.reshape(-1, 2, n_components) # (12800, 2, n_comp)\n",
    "    data_pca = data_pca.transpose(0, 2, 1)  # (n_samples, n_comp, 2)\n",
    "    \n",
    "    return data_pca, scaler, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   -18     34]\n",
      " [   -42     59]\n",
      " [   113    132]\n",
      " [    87    214]\n",
      " [   198     73]\n",
      " [    20     36]\n",
      " [   -15      4]\n",
      " [    -3     87]\n",
      " [    13     73]\n",
      " [   102     95]\n",
      " [    53     98]\n",
      " [    26    -48]\n",
      " [    81    -13]\n",
      " [   169      1]\n",
      " [   167     69]\n",
      " [   181    112]\n",
      " [    96     28]\n",
      " [    50     38]\n",
      " [    80    213]\n",
      " [   152    249]\n",
      " [   134    124]\n",
      " [   196    130]\n",
      " [   244     63]\n",
      " [    90     12]\n",
      " [    72   -190]\n",
      " [   208   -177]\n",
      " [   348    -26]\n",
      " [   420    222]\n",
      " [   312    337]\n",
      " [    85    268]\n",
      " [   -10     79]\n",
      " [   103    104]\n",
      " [    98    283]\n",
      " [   -56    237]\n",
      " [   -45    145]\n",
      " [     4    240]\n",
      " [   213    -86]\n",
      " [   333    218]\n",
      " [   137    362]\n",
      " [  -279    305]\n",
      " [  -123     89]\n",
      " [    74     72]\n",
      " [   136     79]\n",
      " [   171    289]\n",
      " [   162    454]\n",
      " [    58    241]\n",
      " [   -23    108]\n",
      " [   -31     77]\n",
      " [    15     92]\n",
      " [    59    234]\n",
      " [   101   2607]\n",
      " [  -997  11360]\n",
      " [ -2819  15324]\n",
      " [ -3083  10353]\n",
      " [  2186  -4785]\n",
      " [  9230  -9419]\n",
      " [ 13802  -2065]\n",
      " [ 12403   4833]\n",
      " [  5800   8553]\n",
      " [ -2127   9586]\n",
      " [ -6076   8411]\n",
      " [ -6056   5238]\n",
      " [ -3184   1715]\n",
      " [  -339   1828]\n",
      " [   358   5871]\n",
      " [ -1470   2497]\n",
      " [  -899  -9903]\n",
      " [  1869 -13874]\n",
      " [  1583  -3808]\n",
      " [ -2467   9500]\n",
      " [ -6829   7739]\n",
      " [ -6654  -2049]\n",
      " [ -1445  -2955]\n",
      " [  1746   1192]\n",
      " [   724    993]\n",
      " [ -1836  -3614]\n",
      " [ -1302  -6404]\n",
      " [  1566  -2851]\n",
      " [  2899    -82]\n",
      " [  2125   -253]\n",
      " [   441  -1036]\n",
      " [  -248   -406]\n",
      " [  -262    752]\n",
      " [  -491    450]\n",
      " [  -637   -421]\n",
      " [   666   -997]\n",
      " [  2602   -703]\n",
      " [  1791   -281]\n",
      " [  -486  -2220]\n",
      " [ -1310  -3664]\n",
      " [   446  -2783]\n",
      " [  3290   -263]\n",
      " [  2994    807]\n",
      " [   644   -277]\n",
      " [  -324   -956]\n",
      " [    29   -364]\n",
      " [  -625    377]\n",
      " [ -2479     80]\n",
      " [ -2999  -1341]\n",
      " [  -643  -1758]\n",
      " [  2303  -2759]\n",
      " [  2796   -958]\n",
      " [  -179    825]\n",
      " [ -3116   1494]\n",
      " [ -1956    869]\n",
      " [   463   -225]\n",
      " [  1370   -395]\n",
      " [  1110    704]\n",
      " [   670   1576]\n",
      " [   201    893]\n",
      " [  -749    -20]\n",
      " [ -1332   -384]\n",
      " [  -618   -130]\n",
      " [   -60    154]\n",
      " [   -95     79]\n",
      " [  -366   -306]\n",
      " [   -79   -249]\n",
      " [   579   -428]\n",
      " [   570   -395]\n",
      " [    81    194]\n",
      " [  -254    421]\n",
      " [  -679    153]\n",
      " [  -697   -355]\n",
      " [  -298   -690]\n",
      " [    -7   -658]\n",
      " [  -126   -556]\n",
      " [  -169   -344]\n",
      " [    82   -192]\n",
      " [  -392   -604]\n",
      " [ -1635  -1010]\n",
      " [ -1560   -851]\n",
      " [  -310    -41]\n",
      " [  -183    198]\n",
      " [  -868   -384]\n",
      " [  -620   -902]\n",
      " [   310   -946]\n",
      " [   713   -318]\n",
      " [   376    116]\n",
      " [    65    -47]\n",
      " [  -183   -757]\n",
      " [  -117   -997]\n",
      " [   234   -456]\n",
      " [   410   -133]\n",
      " [   383    -81]\n",
      " [   146   -320]\n",
      " [    66   -289]\n",
      " [    86   -256]\n",
      " [    33   -215]\n",
      " [   -56    -42]\n",
      " [   117   -354]\n",
      " [   371   -382]\n",
      " [   358     30]\n",
      " [   220    273]\n",
      " [     0    245]\n",
      " [  -256   -154]\n",
      " [   -20   -419]\n",
      " [   357   -489]\n",
      " [   443   -419]\n",
      " [    60   -115]\n",
      " [  -128    -67]\n",
      " [   -55   -407]\n",
      " [   257   -310]\n",
      " [   191     59]\n",
      " [    95    138]\n",
      " [    26     23]\n",
      " [    16   -196]\n",
      " [    44   -131]\n",
      " [   119     10]\n",
      " [    85    -11]\n",
      " [    16   -260]\n",
      " [    88   -207]\n",
      " [   228     63]\n",
      " [   243    237]\n",
      " [    87    127]\n",
      " [  -146    -87]\n",
      " [  -195   -119]\n",
      " [   -52    -49]\n",
      " [    49    -62]\n",
      " [    88    -98]\n",
      " [   118   -140]\n",
      " [   167     28]\n",
      " [   154     59]\n",
      " [    23     81]\n",
      " [  -116    -49]\n",
      " [    16   -142]\n",
      " [   261    -23]\n",
      " [   260      7]\n",
      " [   191    -76]\n",
      " [   170    -62]\n",
      " [   298    -79]\n",
      " [   290    -77]\n",
      " [   212    -34]\n",
      " [   184   -234]\n",
      " [   311   -216]\n",
      " [    98    -89]\n",
      " [     2    -34]\n",
      " [    12     50]\n",
      " [    89    -53]\n",
      " [   140     21]\n",
      " [   181     35]\n",
      " [   234     30]\n",
      " [   117    -65]\n",
      " [    82     -6]\n",
      " [    10     35]\n",
      " [    46     17]\n",
      " [    62      2]\n",
      " [     5    -89]\n",
      " [    40   -109]\n",
      " [    83    -69]\n",
      " [    73     -9]\n",
      " [    50    -30]\n",
      " [   150   -102]\n",
      " [   168     98]\n",
      " [   157     29]\n",
      " [    35    -69]\n",
      " [    80    -40]\n",
      " [   169     15]\n",
      " [   162     81]\n",
      " [    47     -6]\n",
      " [     9   -130]\n",
      " [    53    -70]\n",
      " [   166     13]\n",
      " [   149     55]\n",
      " [    96    -21]\n",
      " [    78   -146]\n",
      " [    95    -73]\n",
      " [    75     41]\n",
      " [    92     79]\n",
      " [   162     10]\n",
      " [   127    -43]\n",
      " [   106   -111]\n",
      " [    70   -123]\n",
      " [   110   -103]\n",
      " [    94      3]\n",
      " [    46     20]\n",
      " [    56    -59]\n",
      " [    65   -147]\n",
      " [   110    -66]\n",
      " [    58    -38]\n",
      " [    40      7]\n",
      " [    64    -10]\n",
      " [   103     37]\n",
      " [    88    -35]\n",
      " [   228    -52]\n",
      " [   250     86]\n",
      " [    60    102]\n",
      " [  -176    128]\n",
      " [   -53     59]\n",
      " [    66    170]\n",
      " [    24     85]\n",
      " [   133    326]]\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Train -----------------\n",
    "# Feature Extraction\n",
    "alice_train_CIRs = trainCIR[:, alice_channel, :, :]  # (6400, 251, 2)\n",
    "eve_train_CIRs = trainCIR[:, eve_channel, :, :]  # (6400, 251, 2)\n",
    "train_cirs = np.vstack((alice_train_CIRs, eve_train_CIRs))  # (12800, 251, 2)\n",
    "print(alice_train_CIRs[0])\n",
    "#  PCA\n",
    "train_cirs_pca, scaler, pca = apply_pca(train_cirs, n_components=n_comp) # (12800, n_comp, 2)\n",
    "\n",
    "# Labels\n",
    "alice_train_labels = np.zeros(alice_train_CIRs.shape[0])  # '0' for Alice.\n",
    "eve_train_labels = np.ones(eve_train_CIRs.shape[0])  # '1' for Eve.\n",
    "train_labels = np.hstack((alice_train_labels, eve_train_labels)) # (12800,)\n",
    "\n",
    "train_features = train_cirs_pca.reshape(train_cirs_pca.shape[0], -1) # (12800, n_comp * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Test -----------------\n",
    "# Feature Extraction\n",
    "alice_test_CIRs = testCIR[:, alice_channel, :, :]\n",
    "eve_test_CIRs = testCIR[:, eve_channel, :, :]\n",
    "test_cirs = np.vstack((alice_test_CIRs, eve_test_CIRs))  # (3200, 251, 2)\n",
    "\n",
    "# PCA\n",
    "reshaped_test_cirs = test_cirs.reshape(-1, 251)\n",
    "test_cirs_scaled = scaler.transform(reshaped_test_cirs)\n",
    "test_cirs_pca = pca.transform(test_cirs_scaled)  # (3200 * 2, 4)\n",
    "# Reshape to original\n",
    "test_cirs_pca = test_cirs_pca.reshape(-1, 2, n_comp)  # (3200, 2, 4)\n",
    "test_cirs_pca = test_cirs_pca.transpose(0, 2, 1)  # (3200, 4, 2)\n",
    "\n",
    "# Labels\n",
    "alice_test_labels = np.zeros(alice_test_CIRs.shape[0])  # Label '0' for Alice.\n",
    "eve_test_labels = np.ones(eve_test_CIRs.shape[0])  # Label '1' for Eve.\n",
    "test_labels = np.hstack((alice_test_labels, eve_test_labels)) # (3200,)\n",
    "\n",
    "test_features = test_cirs_pca.reshape(test_cirs_pca.shape[0], -1) # (3200, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Classification -----------------\n",
    "# Step 5: Classification using K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_features, train_labels)\n",
    "\n",
    "predictions = knn.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 54.41%\n",
      "tp: 799\n",
      "tn: 942\n",
      "fp: 658\n",
      "fn: 801\n",
      "MDR: 0.41125\n",
      "FAR: 0.500625\n",
      "AR: 0.5440625\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Evaluation -----------------\n",
    "# accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Classification Accuracy: {accuracy * 100:.2f}%\")\n",
    "# confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(test_labels, predictions, labels=[0, 1]).ravel()\n",
    "\n",
    "print(f\"tp: {tp}\")\n",
    "print(f\"tn: {tn}\")\n",
    "print(f\"fp: {fp}\")\n",
    "print(f\"fn: {fn}\")\n",
    "\n",
    "# Missed Detection Rate (MDR)\n",
    "MDR = fp / (fp + tn)\n",
    "\n",
    "# False Alarm Rate (FAR)\n",
    "FAR = fn / (fn + tp)\n",
    "\n",
    "# Gamma calculation\n",
    "gamma = (tp + fn) / (tn + fp)\n",
    "\n",
    "# Authentication Rate (AR)\n",
    "AR = (tp + gamma * tn) / ((tp + fn) + gamma * (tn + fp))\n",
    "\n",
    "print(f\"MDR: {MDR}\")\n",
    "print(f\"FAR: {FAR}\")\n",
    "print(f\"AR: {AR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 1)\n",
      "(251, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Create a dummy dataset (251 samples, 2 features)\n",
    "data = np.random.randn(100, 251, 2)\n",
    "\n",
    "data_pca = []\n",
    "for cir in data[:2]:\n",
    "    \n",
    "    #(251, 2)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    cir_scaled = scaler.fit_transform(cir) # Shape: (251, 2)    \n",
    "    \n",
    "    # PCA (sample > feature)\n",
    "    pca = PCA(n_components=1)\n",
    "    cir_pca_transformed = pca.fit_transform(cir_scaled)  # Shape: (251, n_components)\n",
    "    print(cir_pca_transformed.shape)\n",
    "    # data_pca.append(cir_pca_transformed)\n",
    "\n",
    "# data_pca = np.array(data_pca)  # Shape: (10, 251, 1)\n",
    "# print(data_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 2)\n",
      "Top 4 components based on product:\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "# data = np.loadtxt('prompt_sparse.txt')\n",
    "data = alice_train_CIRs[0]\n",
    "print(data.shape)\n",
    "# Calculate a metric (e.g., product of pairs)\n",
    "products = np.abs(data[:, 0] * data[:, 1])  # Using absolute value for significance\n",
    "\n",
    "# Sort by the metric in descending order\n",
    "top_indices = np.argsort(products)[::-1][:4]\n",
    "top_components = data[top_indices]\n",
    "\n",
    "print(\"Top 4 components based on product:\")\n",
    "print(top_components.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
