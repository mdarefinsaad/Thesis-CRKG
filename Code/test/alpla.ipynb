{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9797, 15, 251, 2)\n"
     ]
    }
   ],
   "source": [
    "# ALPLA demo- Implementation with a small scale dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# import sys\n",
    "# print(\"Python version\")\n",
    "# print(sys.version)\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Load measurement file:\n",
    "measurement = np.load('dataset/meas_symm_1.npz', allow_pickle=False)\n",
    "header, data = measurement['header'], measurement['data']\n",
    "\n",
    "# print(header.dtype)\n",
    "print(data['cirs'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Understanding Array\n",
    "# Our testing CIR dataset\n",
    "new_data = {\n",
    "    'cirs': np.array(\n",
    "        [\n",
    "            [\n",
    "                [\n",
    "                    [1, 2],\n",
    "                    [3, 4],\n",
    "                    [5, 6]\n",
    "                ],\n",
    "                [\n",
    "                    [9, 10],\n",
    "                    [11, 12],\n",
    "                    [13, 14]\n",
    "                ],\n",
    "                [\n",
    "                    [17, 18],\n",
    "                    [19, 20],\n",
    "                    [21, 22]\n",
    "                ]\n",
    "            ],\n",
    "            [\n",
    "                [\n",
    "                    [25, 26],\n",
    "                    [27, 28],\n",
    "                    [29, 30]\n",
    "                ],\n",
    "                [\n",
    "                    [33, 34],\n",
    "                    [35, 36],\n",
    "                    [37, 38]\n",
    "                ],\n",
    "                [\n",
    "                    [41, 42],\n",
    "                    [43, 44],\n",
    "                    [45, 46]\n",
    "                ]\n",
    "            ],\n",
    "            [\n",
    "                [\n",
    "                    [49, 50],\n",
    "                    [51, 52],\n",
    "                    [53, 54]\n",
    "                ],\n",
    "                [\n",
    "                    [57, 58],\n",
    "                    [59, 60],\n",
    "                    [61, 62]\n",
    "                ],\n",
    "                [\n",
    "                    [65, 66],\n",
    "                    [67, 68],\n",
    "                    [69, 70]\n",
    "                ]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1 - Extract real and imaginary parts for Alice and Eve (assuming channels 0 and 1)\n",
    "alice_real = new_data['cirs'][:, 0, :, 0]\n",
    "alice_imag = new_data['cirs'][:, 0, :, 1]\n",
    "\n",
    "eve_real = new_data['cirs'][:, 1, :, 0]\n",
    "eve_imag = new_data['cirs'][:, 1, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Real:\n",
      "[[ 1  3  5]\n",
      " [25 27 29]\n",
      " [49 51 53]]\n",
      "Alice Imaginary:\n",
      "[[ 2  4  6]\n",
      " [26 28 30]\n",
      " [50 52 54]]\n",
      "\n",
      "Eve Real:\n",
      "[[ 9 11 13]\n",
      " [33 35 37]\n",
      " [57 59 61]]\n",
      "Eve Imaginary:\n",
      "[[10 12 14]\n",
      " [34 36 38]\n",
      " [58 60 62]]\n"
     ]
    }
   ],
   "source": [
    "# Print\n",
    "print('Alice Real:')\n",
    "print(alice_real)\n",
    "print('Alice Imaginary:')\n",
    "print(alice_imag)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Eve Real:')\n",
    "print(eve_real)\n",
    "print('Eve Imaginary:')\n",
    "print(eve_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.2 - Compute magnitudes\n",
    "alice_mag = np.sqrt(alice_real**2 + alice_imag**2)\n",
    "eve_mag = np.sqrt(eve_real**2 + eve_imag**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Magnitude:\n",
      "[[ 2.23606798  5.          7.81024968]\n",
      " [36.06937759 38.89730068 41.72529209]\n",
      " [70.00714249 72.83543094 75.66372975]]\n",
      "\n",
      "Eve Magnitude:\n",
      "[[13.45362405 16.2788206  19.10497317]\n",
      " [47.38143096 50.20956084 53.03772242]\n",
      " [81.32035416 84.14867795 86.97700846]]\n"
     ]
    }
   ],
   "source": [
    "# Print\n",
    "print('Alice Magnitude:')\n",
    "print(alice_mag)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Eve Magnitude:')\n",
    "print(eve_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.3 - Flatten the arrays\n",
    "\n",
    "# Flatten features for Alice\n",
    "alice_real_flat = alice_real.flatten()\n",
    "alice_imag_flat = alice_imag.flatten()\n",
    "alice_mag_flat = alice_mag.flatten()\n",
    "\n",
    "# Flatten features for Eve\n",
    "eve_real_flat = eve_real.flatten()\n",
    "eve_imag_flat = eve_imag.flatten()\n",
    "eve_mag_flat = eve_mag.flatten()\n",
    "\n",
    "# We flatten the arrays to make them suitable for the MinMaxScaler\n",
    "# We flat all three(real, imaginary and magnitude) parts of the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Real Flat:\n",
      "[ 1  3  5 25 27 29 49 51 53]\n",
      "\n",
      "Alice Imaginary Flat:\n",
      "[ 2  4  6 26 28 30 50 52 54]\n",
      "\n",
      "Alice Magnitude Flat:\n",
      "[ 2.23606798  5.          7.81024968 36.06937759 38.89730068 41.72529209\n",
      " 70.00714249 72.83543094 75.66372975]\n",
      "\n",
      "\n",
      "Eve Real Flat:\n",
      "[ 9 11 13 33 35 37 57 59 61]\n",
      "\n",
      "Eve Imaginary Flat:\n",
      "[10 12 14 34 36 38 58 60 62]\n",
      "\n",
      "Eve Magnitude Flat:\n",
      "[13.45362405 16.2788206  19.10497317 47.38143096 50.20956084 53.03772242\n",
      " 81.32035416 84.14867795 86.97700846]\n"
     ]
    }
   ],
   "source": [
    "# Print\n",
    "print('Alice Real Flat:')\n",
    "print(alice_real_flat)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Alice Imaginary Flat:')\n",
    "print(alice_imag_flat)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Alice Magnitude Flat:')\n",
    "print(alice_mag_flat)\n",
    "\n",
    "print() \n",
    "print()\n",
    "\n",
    "print('Eve Real Flat:')\n",
    "print(eve_real_flat)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Eve Imaginary Flat:')\n",
    "print(eve_imag_flat)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Eve Magnitude Flat:')\n",
    "print(eve_mag_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.4 - Combine features (making a feature vector)\n",
    "alice_features = np.column_stack((alice_real_flat, alice_imag_flat, alice_mag_flat))\n",
    "eve_features = np.column_stack((eve_real_flat, eve_imag_flat, eve_mag_flat))\n",
    "\n",
    "# By doing np.column_stack, we are making a feature vector of the signal (combining all three parts of the signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Combined Features:\n",
      "[[ 1.          2.          2.23606798]\n",
      " [ 3.          4.          5.        ]\n",
      " [ 5.          6.          7.81024968]\n",
      " [25.         26.         36.06937759]\n",
      " [27.         28.         38.89730068]\n",
      " [29.         30.         41.72529209]\n",
      " [49.         50.         70.00714249]\n",
      " [51.         52.         72.83543094]\n",
      " [53.         54.         75.66372975]]\n",
      "\n",
      "Eve Combined Features:\n",
      "[[ 9.         10.         13.45362405]\n",
      " [11.         12.         16.2788206 ]\n",
      " [13.         14.         19.10497317]\n",
      " [33.         34.         47.38143096]\n",
      " [35.         36.         50.20956084]\n",
      " [37.         38.         53.03772242]\n",
      " [57.         58.         81.32035416]\n",
      " [59.         60.         84.14867795]\n",
      " [61.         62.         86.97700846]]\n"
     ]
    }
   ],
   "source": [
    "print('Alice Combined Features:')\n",
    "print(alice_features)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Eve Combined Features:')\n",
    "print(eve_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.5 - Normalize the data (to train the model)\n",
    "scaler = MinMaxScaler()\n",
    "alice_features_scaled = scaler.fit_transform(alice_features)\n",
    "eve_features_scaled = scaler.fit_transform(eve_features) # Used the samne way as Alice's data was scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Scaled Features:\n",
      "[[0.         0.         0.        ]\n",
      " [0.03846154 0.03846154 0.03764156]\n",
      " [0.07692308 0.07692308 0.07591392]\n",
      " [0.46153846 0.46153846 0.46077063]\n",
      " [0.5        0.5        0.49928367]\n",
      " [0.53846154 0.53846154 0.53779765]\n",
      " [0.92307692 0.92307692 0.92296381]\n",
      " [0.96153846 0.96153846 0.96148183]\n",
      " [1.         1.         1.        ]]\n",
      "\n",
      "Eve Scaled Features:\n",
      "[[0.         0.         0.        ]\n",
      " [0.03846154 0.03846154 0.03842582]\n",
      " [0.07692308 0.07692308 0.07686465]\n",
      " [0.46153846 0.46153846 0.461456  ]\n",
      " [0.5        0.5        0.49992172]\n",
      " [0.53846154 0.53846154 0.53838787]\n",
      " [0.92307692 0.92307692 0.92306319]\n",
      " [0.96153846 0.96153846 0.96153155]\n",
      " [1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Print\n",
    "print('Alice Scaled Features:')\n",
    "print(alice_features_scaled)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Eve Scaled Features:')\n",
    "print(eve_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2.1 - Train OCC-SVM for Alice\n",
    "occ_svm = OneClassSVM(kernel='linear', nu=0.01)  # You can experiment with other kernels like 'rbf', 'poly', 'sigmoid'\n",
    "occ_svm.fit(alice_features_scaled)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(occ_svm, 'occ_svm_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.1 - Test Incoming Signals\n",
    "occ_svm = joblib.load('occ_svm_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Example incoming signal data for testing (using the same dataset here for simplicity)\n",
    "incoming_data = new_data['cirs']\n",
    "\n",
    "# Extract features for testing\n",
    "incoming_real = incoming_data[:, 0, :, 0]\n",
    "incoming_imag = incoming_data[:, 0, :, 1]\n",
    "incoming_mag = np.sqrt(incoming_real**2 + incoming_imag**2)\n",
    "\n",
    "# Combine and normalize features\n",
    "incoming_features_vector = np.column_stack((incoming_real.flatten(), incoming_imag.flatten(), incoming_mag.flatten()))\n",
    "# Scaled the incoming features using the same scaler used for Alice\n",
    "incoming_features_scaled = scaler.transform(incoming_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using OCC-SVM\n",
    "predictions = occ_svm.predict(incoming_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Legitimate signals: 0\n",
      "Illegitimate signals: 9\n"
     ]
    }
   ],
   "source": [
    "# Check predictions (1 for inliers/legitimate, -1 for outliers/illegitimate)\n",
    "print(predictions)\n",
    "legitimate = predictions == 1\n",
    "illegitimate = predictions == -1\n",
    "print(\"Legitimate signals:\", legitimate.sum())\n",
    "print(\"Illegitimate signals:\", illegitimate.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
