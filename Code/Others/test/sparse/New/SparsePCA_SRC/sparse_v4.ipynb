{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice_train_CIRs: (800, 251, 2)\n",
      "train_cirs: (1600, 251, 2)\n",
      "train_cirs_dict: (1600, 20)\n",
      "Dictionary : (502, 20)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [502, 20]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m testSample \u001b[38;5;129;01min\u001b[39;00m test_cirs_dict:\n\u001b[0;32m--> 108\u001b[0m     predicted_class \u001b[38;5;241m=\u001b[39m classify_signal(testSample, D, train_labels)\n\u001b[1;32m    109\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(predicted_class)\n\u001b[1;32m    111\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "Cell \u001b[0;32mIn[1], line 90\u001b[0m, in \u001b[0;36mclassify_signal\u001b[0;34m(tSample, D, trainLabel)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_signal\u001b[39m(tSample, D, trainLabel):\n\u001b[0;32m---> 90\u001b[0m     coefficients \u001b[38;5;241m=\u001b[39m find_sparse_coefficients(tSample, D)\n\u001b[1;32m     91\u001b[0m     residuals \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     93\u001b[0m     unique_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(trainLabel)  \u001b[38;5;66;03m# Classes: 0 and 1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m, in \u001b[0;36mfind_sparse_coefficients\u001b[0;34m(tSample, D, n_nonzero_coefs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_sparse_coefficients\u001b[39m(tSample, D, n_nonzero_coefs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m     76\u001b[0m     omp \u001b[38;5;241m=\u001b[39m OrthogonalMatchingPursuit(n_nonzero_coefs\u001b[38;5;241m=\u001b[39mn_nonzero_coefs)\n\u001b[0;32m---> 77\u001b[0m     omp\u001b[38;5;241m.\u001b[39mfit(D, tSample)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m omp\u001b[38;5;241m.\u001b[39mcoef_\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/linear_model/_omp.py:772\u001b[0m, in \u001b[0;36mOrthogonalMatchingPursuit.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    757\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model using X, y as training data.\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \n\u001b[1;32m    759\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m        Returns an instance of self.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    773\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    775\u001b[0m     X, y, X_offset, y_offset, X_scale, Gram, Xy \u001b[38;5;241m=\u001b[39m _pre_fit(\n\u001b[1;32m    776\u001b[0m         X, y, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecompute, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    777\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/utils/validation.py:1291\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1273\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1274\u001b[0m     X,\n\u001b[1;32m   1275\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1287\u001b[0m )\n\u001b[1;32m   1289\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1291\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/utils/validation.py:460\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    458\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    463\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [502, 20]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "\n",
    "# Set numpy print options for better readability\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Loading dataset\n",
    "measurement = np.load('../../../dataset/meas_symm_1.npz', allow_pickle=False)\n",
    "n_comp = 20  # Increased number of components for better representation\n",
    "header, data = measurement['header'], measurement['data']\n",
    "data_cir = data['cirs'][:1000]\n",
    "\n",
    "trainCIR, testCIR = train_test_split(data_cir, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def apply_dictionary_learning(data, n_components):\n",
    "    # Reshape the data to 2D: (samples, features)\n",
    "    reshaped_data = data.reshape(data.shape[0], -1)\n",
    "    \n",
    "    # Scale the data to have zero mean and unit variance\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(reshaped_data)\n",
    "    \n",
    "    # Dictionary Learning\n",
    "    dict_learner = DictionaryLearning(n_components=n_components, transform_algorithm='omp', random_state=42)\n",
    "    data_dict = dict_learner.fit_transform(data_scaled)\n",
    "    \n",
    "    return data_dict, scaler, dict_learner\n",
    "\n",
    "\n",
    "alice_channel = 3  # Legitimate channel\n",
    "eve_channel = 6    # Illegitimate channel\n",
    "\n",
    "# Data and Feature Extraction\n",
    "alice_train_CIRs = trainCIR[:, alice_channel, :, :]\n",
    "eve_train_CIRs = trainCIR[:, eve_channel, :, :]\n",
    "print(f\"alice_train_CIRs: {alice_train_CIRs.shape}\")\n",
    "\n",
    "train_cirs = np.vstack((alice_train_CIRs, eve_train_CIRs))  \n",
    "print(f\"train_cirs: {train_cirs.shape}\")\n",
    "\n",
    "# Dictionary Learning -> training data\n",
    "train_cirs_dict, scaler, dict_learner = apply_dictionary_learning(train_cirs, n_components=n_comp)\n",
    "print(f\"train_cirs_dict: {train_cirs_dict.shape}\")\n",
    "\n",
    "# Labels\n",
    "alice_train_labels = np.zeros(alice_train_CIRs.shape[0])  \n",
    "eve_train_labels = np.ones(eve_train_CIRs.shape[0])       \n",
    "train_labels = np.hstack((alice_train_labels, eve_train_labels))\n",
    "\n",
    "D = dict_learner.components_.T  # Shape: (features, n_components)\n",
    "print(f'Dictionary : {D.shape}')\n",
    "\n",
    "# Extract and prepare test data\n",
    "alice_test_CIRs = testCIR[:, alice_channel, :, :]\n",
    "eve_test_CIRs = testCIR[:, eve_channel, :, :]\n",
    "test_cirs = np.vstack((alice_test_CIRs, eve_test_CIRs))  \n",
    "\n",
    "# Transform test data with same Scaler and dictionary learner\n",
    "reshaped_test_cirs = test_cirs.reshape(test_cirs.shape[0], -1)\n",
    "test_cirs_scaled = scaler.transform(reshaped_test_cirs)\n",
    "test_cirs_dict = dict_learner.transform(test_cirs_scaled)\n",
    "\n",
    "# Labels\n",
    "alice_test_labels = np.zeros(alice_test_CIRs.shape[0])  \n",
    "eve_test_labels = np.ones(eve_test_CIRs.shape[0])       \n",
    "test_labels = np.hstack((alice_test_labels, eve_test_labels))\n",
    "\n",
    "# Coefficients calculation\n",
    "def find_sparse_coefficients(tSample, D, n_nonzero_coefs=15):\n",
    "    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=n_nonzero_coefs)\n",
    "    omp.fit(D, tSample)\n",
    "    return omp.coef_\n",
    "\n",
    "# Calculate residual\n",
    "def calculate_residual(tSample, coefficients, class_indices, D):\n",
    "    coef_class = np.zeros_like(coefficients)\n",
    "    coef_class[class_indices] = coefficients[class_indices]  # Keep only coefficients for the specified class\n",
    "    reconstructed_signal = D @ coef_class\n",
    "    residual = np.linalg.norm(tSample - reconstructed_signal)\n",
    "    return residual\n",
    "\n",
    "# Classification function\n",
    "def classify_signal(tSample, D, trainLabel):\n",
    "    coefficients = find_sparse_coefficients(tSample, D)\n",
    "    residuals = []\n",
    "\n",
    "    unique_classes = np.unique(trainLabel)  # Classes: 0 and 1\n",
    "    for class_label in unique_classes:\n",
    "        class_indices = np.where(trainLabel == class_label)[0]  # Indices of atoms belonging to the class\n",
    "        residual = calculate_residual(tSample, coefficients, class_indices, D)\n",
    "        residuals.append(residual)\n",
    "\n",
    "    # Predict the class with the smallest residual\n",
    "    min_residual_index = np.argmin(residuals)\n",
    "    predicted_class = unique_classes[min_residual_index]\n",
    "    return predicted_class\n",
    "\n",
    "# Classify the test data and evaluate the model\n",
    "predictions = []\n",
    "\n",
    "for testSample in test_cirs_dict:\n",
    "    predicted_class = classify_signal(testSample, D, train_labels)\n",
    "    predictions.append(predicted_class)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "accuracy = np.mean(predictions == test_labels)\n",
    "print(f\"Classification Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate confusion matrix and performance metrics\n",
    "print(f\"\\nTotal testing samples: {test_labels.shape}\")\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_labels, predictions, labels=[0, 1]).ravel()\n",
    "\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "\n",
    "# Missed Detection Rate (MDR)\n",
    "MDR = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "\n",
    "# False Alarm Rate (FAR)\n",
    "FAR = fn / (fn + tp) if (fn + tp) != 0 else 0\n",
    "\n",
    "# Gamma calculation\n",
    "gamma = (tp + fn) / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# Authentication Rate (AR)\n",
    "AR = (tp + gamma * tn) / ((tp + fn) + gamma * (tn + fp)) if ((tp + fn) + gamma * (tn + fp)) != 0 else 0\n",
    "\n",
    "print(f\"MDR: {MDR}\")\n",
    "print(f\"FAR: {FAR}\")\n",
    "print(f\"AR: {AR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
