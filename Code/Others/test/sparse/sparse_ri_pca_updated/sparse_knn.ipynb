{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m8000\u001b[39m)  \u001b[38;5;66;03m# Random binary labels, 0 for Eve, 1 for Alice\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Apply Dictionary Learning using the function\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m data_reduced \u001b[38;5;241m=\u001b[39m apply_sparse_representation(data, no_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Step 2: Flatten each CIR sample to a 1D array\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Original shape: (8000, 4, 2) --> New shape: (8000, 8)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m data_flattened \u001b[38;5;241m=\u001b[39m data_reduced\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m8000\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m, in \u001b[0;36mapply_sparse_representation\u001b[0;34m(data, no_components)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Apply Dictionary Learning to reduce the 251 dimension to no_components\u001b[39;00m\n\u001b[1;32m     24\u001b[0m dict_learning \u001b[38;5;241m=\u001b[39m DictionaryLearning(n_components\u001b[38;5;241m=\u001b[39mno_components, transform_algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlasso_lars\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m data_sparse \u001b[38;5;241m=\u001b[39m dict_learning\u001b[38;5;241m.\u001b[39mfit_transform(data_reshaped)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Reshape data back to original structure with reduced dimension\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# New shape: (n_samples, no_components, 2)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m data_reduced \u001b[38;5;241m=\u001b[39m data_sparse\u001b[38;5;241m.\u001b[39mreshape(n_samples, no_components, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:1681\u001b[0m, in \u001b[0;36mDictionaryLearning.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[0;32m-> 1681\u001b[0m V, U, E, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m _dict_learning(\n\u001b[1;32m   1682\u001b[0m     X,\n\u001b[1;32m   1683\u001b[0m     n_components,\n\u001b[1;32m   1684\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[1;32m   1685\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m   1686\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1687\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   1688\u001b[0m     method_max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_max_iter,\n\u001b[1;32m   1689\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m   1690\u001b[0m     code_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode_init,\n\u001b[1;32m   1691\u001b[0m     dict_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict_init,\n\u001b[1;32m   1692\u001b[0m     callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback,\n\u001b[1;32m   1693\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1694\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m   1695\u001b[0m     return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1696\u001b[0m     positive_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive_dict,\n\u001b[1;32m   1697\u001b[0m     positive_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive_code,\n\u001b[1;32m   1698\u001b[0m )\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_ \u001b[38;5;241m=\u001b[39m U\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_ \u001b[38;5;241m=\u001b[39m E\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:620\u001b[0m, in \u001b[0;36m_dict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter, positive_dict, positive_code, method_max_iter)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m% 3i\u001b[39;00m\u001b[38;5;124m (elapsed time: \u001b[39m\u001b[38;5;132;01m% 3i\u001b[39;00m\u001b[38;5;124ms, \u001b[39m\u001b[38;5;132;01m% 4.1f\u001b[39;00m\u001b[38;5;124mmn, current cost \u001b[39m\u001b[38;5;132;01m% 7.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;241m%\u001b[39m (ii, dt, dt \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m, current_cost)\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Update code\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m code \u001b[38;5;241m=\u001b[39m sparse_encode(\n\u001b[1;32m    621\u001b[0m     X,\n\u001b[1;32m    622\u001b[0m     dictionary,\n\u001b[1;32m    623\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    624\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    625\u001b[0m     init\u001b[38;5;241m=\u001b[39mcode,\n\u001b[1;32m    626\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    627\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive_code,\n\u001b[1;32m    628\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mmethod_max_iter,\n\u001b[1;32m    629\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    630\u001b[0m )\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# Update dictionary in place\u001b[39;00m\n\u001b[1;32m    633\u001b[0m _update_dict(\n\u001b[1;32m    634\u001b[0m     dictionary,\n\u001b[1;32m    635\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive_dict,\n\u001b[1;32m    640\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:377\u001b[0m, in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDictionary and X have different numbers of features:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdictionary.shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m X.shape\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dictionary\u001b[38;5;241m.\u001b[39mshape, X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    375\u001b[0m _check_positive_coding(algorithm, positive)\n\u001b[0;32m--> 377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sparse_encode(\n\u001b[1;32m    378\u001b[0m     X,\n\u001b[1;32m    379\u001b[0m     dictionary,\n\u001b[1;32m    380\u001b[0m     gram\u001b[38;5;241m=\u001b[39mgram,\n\u001b[1;32m    381\u001b[0m     cov\u001b[38;5;241m=\u001b[39mcov,\n\u001b[1;32m    382\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39malgorithm,\n\u001b[1;32m    383\u001b[0m     n_nonzero_coefs\u001b[38;5;241m=\u001b[39mn_nonzero_coefs,\n\u001b[1;32m    384\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    385\u001b[0m     copy_cov\u001b[38;5;241m=\u001b[39mcopy_cov,\n\u001b[1;32m    386\u001b[0m     init\u001b[38;5;241m=\u001b[39minit,\n\u001b[1;32m    387\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m    388\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    389\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    390\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive,\n\u001b[1;32m    391\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:432\u001b[0m, in \u001b[0;36m_sparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, verbose, positive)\u001b[0m\n\u001b[1;32m    429\u001b[0m     cov \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(dictionary, X\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 432\u001b[0m     code \u001b[38;5;241m=\u001b[39m _sparse_encode_precomputed(\n\u001b[1;32m    433\u001b[0m         X,\n\u001b[1;32m    434\u001b[0m         dictionary,\n\u001b[1;32m    435\u001b[0m         gram\u001b[38;5;241m=\u001b[39mgram,\n\u001b[1;32m    436\u001b[0m         cov\u001b[38;5;241m=\u001b[39mcov,\n\u001b[1;32m    437\u001b[0m         algorithm\u001b[38;5;241m=\u001b[39malgorithm,\n\u001b[1;32m    438\u001b[0m         regularization\u001b[38;5;241m=\u001b[39mregularization,\n\u001b[1;32m    439\u001b[0m         copy_cov\u001b[38;5;241m=\u001b[39mcopy_cov,\n\u001b[1;32m    440\u001b[0m         init\u001b[38;5;241m=\u001b[39minit,\n\u001b[1;32m    441\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m    442\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    443\u001b[0m         positive\u001b[38;5;241m=\u001b[39mpositive,\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m code\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Enter parallel code block\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:135\u001b[0m, in \u001b[0;36m_sparse_encode_precomputed\u001b[0;34m(X, dictionary, gram, cov, algorithm, regularization, copy_cov, init, max_iter, verbose, positive)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# Not passing in verbose=max(0, verbose-1) because Lars.fit already\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# corrects the verbosity level.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     lasso_lars \u001b[38;5;241m=\u001b[39m LassoLars(\n\u001b[1;32m    127\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    128\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m    134\u001b[0m     )\n\u001b[0;32m--> 135\u001b[0m     lasso_lars\u001b[38;5;241m.\u001b[39mfit(dictionary\u001b[38;5;241m.\u001b[39mT, X\u001b[38;5;241m.\u001b[39mT, Xy\u001b[38;5;241m=\u001b[39mcov)\n\u001b[1;32m    136\u001b[0m     new_code \u001b[38;5;241m=\u001b[39m lasso_lars\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:1198\u001b[0m, in \u001b[0;36mLars.fit\u001b[0;34m(self, X, y, Xy)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     noise \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39muniform(high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjitter, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y))\n\u001b[1;32m   1196\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m noise\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1199\u001b[0m     X,\n\u001b[1;32m   1200\u001b[0m     y,\n\u001b[1;32m   1201\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m   1202\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m   1203\u001b[0m     fit_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_path,\n\u001b[1;32m   1204\u001b[0m     Xy\u001b[38;5;241m=\u001b[39mXy,\n\u001b[1;32m   1205\u001b[0m )\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:1136\u001b[0m, in \u001b[0;36mLars._fit\u001b[0;34m(self, X, y, max_iter, alpha, fit_path, Xy)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_targets):\n\u001b[1;32m   1135\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m Xy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m Xy[:, k]\n\u001b[0;32m-> 1136\u001b[0m     alphas, _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_[k], n_iter_ \u001b[38;5;241m=\u001b[39m lars_path(\n\u001b[1;32m   1137\u001b[0m         X,\n\u001b[1;32m   1138\u001b[0m         y[:, k],\n\u001b[1;32m   1139\u001b[0m         Gram\u001b[38;5;241m=\u001b[39mGram,\n\u001b[1;32m   1140\u001b[0m         Xy\u001b[38;5;241m=\u001b[39mthis_Xy,\n\u001b[1;32m   1141\u001b[0m         copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_X,\n\u001b[1;32m   1142\u001b[0m         copy_Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1143\u001b[0m         alpha_min\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m   1144\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   1145\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   1146\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m   1147\u001b[0m         eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m   1148\u001b[0m         return_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m         return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1150\u001b[0m         positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive,\n\u001b[1;32m   1151\u001b[0m     )\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_\u001b[38;5;241m.\u001b[39mappend(alphas)\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_\u001b[38;5;241m.\u001b[39mappend(n_iter_)\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:218\u001b[0m, in \u001b[0;36mlars_path\u001b[0;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX cannot be None if Gram is not None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse lars_path_gram to avoid passing X and y.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m     )\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _lars_path_solver(\n\u001b[1;32m    219\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    220\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    221\u001b[0m     Xy\u001b[38;5;241m=\u001b[39mXy,\n\u001b[1;32m    222\u001b[0m     Gram\u001b[38;5;241m=\u001b[39mGram,\n\u001b[1;32m    223\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    224\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m    225\u001b[0m     alpha_min\u001b[38;5;241m=\u001b[39malpha_min,\n\u001b[1;32m    226\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    227\u001b[0m     copy_X\u001b[38;5;241m=\u001b[39mcopy_X,\n\u001b[1;32m    228\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    229\u001b[0m     copy_Gram\u001b[38;5;241m=\u001b[39mcopy_Gram,\n\u001b[1;32m    230\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    231\u001b[0m     return_path\u001b[38;5;241m=\u001b[39mreturn_path,\n\u001b[1;32m    232\u001b[0m     return_n_iter\u001b[38;5;241m=\u001b[39mreturn_n_iter,\n\u001b[1;32m    233\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive,\n\u001b[1;32m    234\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/CRKG/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:659\u001b[0m, in \u001b[0;36m_lars_path_solver\u001b[0;34m(X, y, Xy, Gram, n_samples, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    657\u001b[0m alpha[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m C \u001b[38;5;241m/\u001b[39m n_samples\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alpha[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m alpha_min \u001b[38;5;241m+\u001b[39m equality_tolerance:  \u001b[38;5;66;03m# early stopping\u001b[39;00m\n\u001b[0;32m--> 659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(alpha[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m alpha_min) \u001b[38;5;241m>\u001b[39m equality_tolerance:\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;66;03m# interpolation factor 0 <= ss < 1\u001b[39;00m\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    662\u001b[0m             \u001b[38;5;66;03m# In the first iteration, all alphas are zero, the formula\u001b[39;00m\n\u001b[1;32m    663\u001b[0m             \u001b[38;5;66;03m# below would make ss a NaN\u001b[39;00m\n\u001b[1;32m    664\u001b[0m             ss \u001b[38;5;241m=\u001b[39m (prev_alpha[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m alpha_min) \u001b[38;5;241m/\u001b[39m (prev_alpha[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m alpha[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def apply_sparse_representation(data, no_components):\n",
    "    \"\"\"\n",
    "    Apply Dictionary Learning to the 2nd dimension (251 points) of the dataset to obtain a sparse representation.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy.ndarray): The dataset with shape (n_samples, 251, 2).\n",
    "    no_components (int): The number of components to reduce to.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The dataset after applying Dictionary Learning, with shape (n_samples, no_components, 2).\n",
    "    \"\"\"\n",
    "    # Reshape data to apply dictionary learning to the 251 dimension\n",
    "    # Original shape: (n_samples, 251, 2) --> New shape: (n_samples * 2, 251)\n",
    "    n_samples = data.shape[0]\n",
    "    data_reshaped = data.reshape(-1, 251)\n",
    "\n",
    "    # Apply Dictionary Learning to reduce the 251 dimension to no_components\n",
    "    dict_learning = DictionaryLearning(n_components=no_components, transform_algorithm='lasso_lars', random_state=42)\n",
    "    data_sparse = dict_learning.fit_transform(data_reshaped)\n",
    "\n",
    "    # Reshape data back to original structure with reduced dimension\n",
    "    # New shape: (n_samples, no_components, 2)\n",
    "    data_reduced = data_sparse.reshape(n_samples, no_components, 2)\n",
    "\n",
    "    return data_reduced\n",
    "\n",
    "# Generate some example data\n",
    "np.random.seed(42)  # Seed for reproducibility\n",
    "# Dataset shape: (8000 samples, 251 data points, 2 features for real and imaginary)\n",
    "data = np.random.randn(8000, 251, 2)\n",
    "labels = np.random.randint(0, 2, 8000)  # Random binary labels, 0 for Eve, 1 for Alice\n",
    "\n",
    "# Apply Dictionary Learning using the function\n",
    "data_reduced = apply_sparse_representation(data, no_components=4)\n",
    "\n",
    "# Step 2: Flatten each CIR sample to a 1D array\n",
    "# Original shape: (8000, 4, 2) --> New shape: (8000, 8)\n",
    "data_flattened = data_reduced.reshape(8000, -1)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "# 80% for training, 20% for testing\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data_flattened, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create and train the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)  # Using 3 neighbors for classification\n",
    "knn.fit(data_train, labels_train)  # Train the model using the training data\n",
    "\n",
    "# Step 5: Make predictions on the test data\n",
    "labels_pred = knn.predict(data_test)\n",
    "\n",
    "# Step 6: Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
